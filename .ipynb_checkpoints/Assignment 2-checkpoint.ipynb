{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
    "### Due: October 10 at 11:59pm\n",
    "\n",
    "### Name: Matthew De Filippo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33f86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (4600, 57) \n",
      "\n",
      "The type of X is:\n",
      " word_freq_make                float64\n",
      "word_freq_address             float64\n",
      "word_freq_all                 float64\n",
      "word_freq_3d                  float64\n",
      "word_freq_our                 float64\n",
      "word_freq_over                float64\n",
      "word_freq_remove              float64\n",
      "word_freq_internet            float64\n",
      "word_freq_order               float64\n",
      "word_freq_mail                float64\n",
      "word_freq_receive             float64\n",
      "word_freq_will                float64\n",
      "word_freq_people              float64\n",
      "word_freq_report              float64\n",
      "word_freq_addresses           float64\n",
      "word_freq_free                float64\n",
      "word_freq_business            float64\n",
      "word_freq_email               float64\n",
      "word_freq_you                 float64\n",
      "word_freq_credit              float64\n",
      "word_freq_your                float64\n",
      "word_freq_font                float64\n",
      "word_freq_000                 float64\n",
      "word_freq_money               float64\n",
      "word_freq_hp                  float64\n",
      "word_freq_hpl                 float64\n",
      "word_freq_george              float64\n",
      "word_freq_650                 float64\n",
      "word_freq_lab                 float64\n",
      "word_freq_labs                float64\n",
      "word_freq_telnet              float64\n",
      "word_freq_857                 float64\n",
      "word_freq_data                float64\n",
      "word_freq_415                 float64\n",
      "word_freq_85                  float64\n",
      "word_freq_technology          float64\n",
      "word_freq_1999                float64\n",
      "word_freq_parts               float64\n",
      "word_freq_pm                  float64\n",
      "word_freq_direct              float64\n",
      "word_freq_cs                  float64\n",
      "word_freq_meeting             float64\n",
      "word_freq_original            float64\n",
      "word_freq_project             float64\n",
      "word_freq_re                  float64\n",
      "word_freq_edu                 float64\n",
      "word_freq_table               float64\n",
      "word_freq_conference          float64\n",
      "char_freq_;                   float64\n",
      "char_freq_(                   float64\n",
      "char_freq_[                   float64\n",
      "char_freq_!                   float64\n",
      "char_freq_$                   float64\n",
      "char_freq_#                   float64\n",
      "capital_run_length_average    float64\n",
      "capital_run_length_longest      int64\n",
      "capital_run_length_total        int64\n",
      "dtype: object\n",
      "\n",
      "The shape of y is: (4600,) \n",
      "\n",
      "The type of y is: int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_spam\n",
    "(X, y) = load_spam()\n",
    "# TO DO: Print size and type of X and y\n",
    "print(f'The shape of X is: {X.shape} \\n') \n",
    "print(f'The type of X is:\\n {X.dtypes}\\n')\n",
    "\n",
    "print(f'The shape of y is: {y.shape} \\n') \n",
    "print(f'The type of y is: {y.dtypes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running X.isnull().sum() gives:\n",
      "\n",
      "word_freq_make                0\n",
      "word_freq_address             0\n",
      "word_freq_all                 0\n",
      "word_freq_3d                  0\n",
      "word_freq_our                 0\n",
      "word_freq_over                0\n",
      "word_freq_remove              0\n",
      "word_freq_internet            0\n",
      "word_freq_order               0\n",
      "word_freq_mail                0\n",
      "word_freq_receive             0\n",
      "word_freq_will                0\n",
      "word_freq_people              0\n",
      "word_freq_report              0\n",
      "word_freq_addresses           0\n",
      "word_freq_free                0\n",
      "word_freq_business            0\n",
      "word_freq_email               0\n",
      "word_freq_you                 0\n",
      "word_freq_credit              0\n",
      "word_freq_your                0\n",
      "word_freq_font                0\n",
      "word_freq_000                 0\n",
      "word_freq_money               0\n",
      "word_freq_hp                  0\n",
      "word_freq_hpl                 0\n",
      "word_freq_george              0\n",
      "word_freq_650                 0\n",
      "word_freq_lab                 0\n",
      "word_freq_labs                0\n",
      "word_freq_telnet              0\n",
      "word_freq_857                 0\n",
      "word_freq_data                0\n",
      "word_freq_415                 0\n",
      "word_freq_85                  0\n",
      "word_freq_technology          0\n",
      "word_freq_1999                0\n",
      "word_freq_parts               0\n",
      "word_freq_pm                  0\n",
      "word_freq_direct              0\n",
      "word_freq_cs                  0\n",
      "word_freq_meeting             0\n",
      "word_freq_original            0\n",
      "word_freq_project             0\n",
      "word_freq_re                  0\n",
      "word_freq_edu                 0\n",
      "word_freq_table               0\n",
      "word_freq_conference          0\n",
      "char_freq_;                   0\n",
      "char_freq_(                   0\n",
      "char_freq_[                   0\n",
      "char_freq_!                   0\n",
      "char_freq_$                   0\n",
      "char_freq_#                   0\n",
      "capital_run_length_average    0\n",
      "capital_run_length_longest    0\n",
      "capital_run_length_total      0\n",
      "dtype: int64\n",
      "Running y.isnull().sum() gives: 0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "print('Running X.isnull().sum() gives:\\n')\n",
    "print(X.isnull().sum())\n",
    "print(f'Running y.isnull().sum() gives: {y.isnull().sum()}')\n",
    "\n",
    "# By running the above methods on X and y, we see that there are 0 null entries in each\n",
    "# column in the X dataframe and 0 null entries in the y dataseries.\n",
    "\n",
    "# Therefore, there are no missing values and we can proceed to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create X_small and y_small \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_scrap, X_small, y_scrap, y_small = train_test_split(X, y, test_size=0.05, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Size</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(4600, 57)</td>\n",
       "      <td>0.927174</td>\n",
       "      <td>0.935870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(4600, 2)</td>\n",
       "      <td>0.614946</td>\n",
       "      <td>0.593478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(230, 57)</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.804348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Data Size  Training Accuracy  Validation Accuracy\n",
       "0  (4600, 57)           0.927174             0.935870\n",
       "1   (4600, 2)           0.614946             0.593478\n",
       "2   (230, 57)           0.956522             0.804348"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "# Import LogisticRegression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate model LogisticRegression(max_iter=2000); implement with X and y.\n",
    "model_all = LogisticRegression(max_iter=2000)\n",
    "X_train_all, X_val_all, y_train_all, y_val_all = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "model_all.fit(X_train_all, y_train_all)\n",
    "\n",
    "# Instantiate model LogisticRegression(max_iter=2000); implement with first two columns of X and y.\n",
    "model_2col = LogisticRegression(max_iter=2000)\n",
    "X_train_2col, X_val_2col, y_train_2col, y_val_2col = train_test_split(X[['word_freq_make', 'word_freq_address']], y, test_size=0.2, random_state=0)\n",
    "model_2col.fit(X_train_2col, y_train_2col)\n",
    "\n",
    "# Instantiate model LogisticRegression(max_iter=2000); implement with X_small and y_small.\n",
    "model_small = LogisticRegression(max_iter=2000)\n",
    "X_train_small, X_val_small, y_train_small, y_val_small = train_test_split(X_small, y_small, test_size=0.2, random_state=0)\n",
    "model_small.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Creating the results DataFrame.\n",
    "results = pd.DataFrame({'Data Size': [X.shape, X[['word_freq_make', 'word_freq_address']].shape, X_small.shape], \n",
    "                        'Training Accuracy': [model_all.score(X_train_all, y_train_all), model_2col.score(X_train_2col, y_train_2col), model_small.score(X_train_small, y_train_small)], \n",
    "                       'Validation Accuracy': [model_all.score(X_val_all, y_val_all), model_2col.score(X_val_2col, y_val_2col), model_small.score(X_val_small, y_val_small)]})\n",
    "\n",
    "# Print results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "#### Question 1 Response:\n",
    "\n",
    "The best performance is observed when we used the full set of data which resulted in training and accuracy scores of 0.93 and 0.94 respectively.\n",
    "\n",
    "When we reduced the dataset to the first two columns the only, the the training and validation scores were 0.61 and 0.59 respectively. This model exhibited much higher bias and resulted in worse performance.\n",
    "\n",
    "When we used only a 5% subset of the dataset, the performance was also worse. The training and validation scores were approximately 0.96 and 0.80 respectively. This model exhibited more high-variance as the validation score was significantly worse than the training score.\n",
    "\n",
    "#### Question 2 Response:\n",
    "\n",
    "A false positive in this scenario indicates that a given email is predicted to be spam when it is in fact not spam. A false negative indicates that a given email is predicted to not be spam when it is in fact spam. A false positive is worse as important emails could be missed by the user. False negatives are also bad however if the user is not educated and prone to the scams that are often contained in spam emails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc42a305",
   "metadata": {},
   "source": [
    "#### Question 1 Response:\n",
    "Code was based on the provided class examples (particularly Linear Example). Aspects of the overall code structure and layout were modified to suit the specific assignment requirements.\n",
    "\n",
    "#### Question 2 Response:\n",
    "I completed the steps in the order recommended by the assigment (1->2->3->4->5).\n",
    "\n",
    "#### Question 3 Response:\n",
    "I did not use generative AI for the completion of this section.\n",
    "\n",
    "#### Question 4 Response:\n",
    "I did experience some challenges throughout the completion of this section:\n",
    "   - I was a bit confused as to what to do with the spare variables created when the dataset was originally split to create the 5% sections. I thought perhaps the 95% sections should be used later on for a portion of the training data. Reading the discussion board confirmed that these variables were not required.\n",
    "   - I struggled recalling the syntax to create the DataFrame to store the results. I searched Google which helped me remember how to create this data structure using a dictionary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (1030, 8) \n",
      "\n",
      "The type of X is:\n",
      " cement    float64\n",
      "slag      float64\n",
      "ash       float64\n",
      "water     float64\n",
      "splast    float64\n",
      "coarse    float64\n",
      "fine      float64\n",
      "age         int64\n",
      "dtype: object\n",
      "\n",
      "The shape of y is: (1030,) \n",
      "\n",
      "The type of y is: float64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "(X, y) = load_concrete()\n",
    "# TO DO: Print size and type of X and y\n",
    "print(f'The shape of X is: {X.shape} \\n') \n",
    "print(f'The type of X is:\\n {X.dtypes}\\n')\n",
    "\n",
    "print(f'The shape of y is: {y.shape} \\n') \n",
    "print(f'The type of y is: {y.dtypes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running X.isnull().sum() gives:\n",
      "\n",
      "cement    0\n",
      "slag      0\n",
      "ash       0\n",
      "water     0\n",
      "splast    0\n",
      "coarse    0\n",
      "fine      0\n",
      "age       0\n",
      "dtype: int64\n",
      "Running y.isnull().sum() gives: 0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "print('Running X.isnull().sum() gives:\\n')\n",
    "print(X.isnull().sum())\n",
    "print(f'Running y.isnull().sum() gives: {y.isnull().sum()}')\n",
    "\n",
    "# By running the above methods on X and y, we see that there are 0 null entries in each\n",
    "# column in the X dataframe and 0 null entries in the y dataseries.\n",
    "\n",
    "# Therefore, there are no missing values and we can proceed to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b5041945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "\n",
    "# Import LogisticRegression from sklearn.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Instantiate model LogisticRegression().\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "model = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "970c038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (MSE): 110.34550122934108\n",
      "Validation Accuracy (MSE): 95.63533482690428\n",
      "Training Accuracy (R^2): 0.6090710418548884\n",
      "Validation Accuracy (R^2): 0.6368981103411242\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Use the model to make predictions using both the training and validation sets.\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_val = model.predict(X_val)\n",
    "\n",
    "# Calculating the training and validation accuracy using mean squared error.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "linear_mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "linear_mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "\n",
    "# Calculating the training and validation accuracy using R2 score.\n",
    "linear_r2_train = model.score(X_train, y_train)\n",
    "linear_r2_val = model.score(X_val, y_val)\n",
    "\n",
    "# Printing the results to the display.\n",
    "print(f\"Training Accuracy (MSE): {linear_mse_train}\")\n",
    "print(f\"Validation Accuracy (MSE): {linear_mse_val}\")\n",
    "print(f\"Training Accuracy (R^2): {linear_r2_train}\")\n",
    "print(f\"Validation Accuracy (R^2): {linear_r2_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE Score</th>\n",
       "      <td>110.345501</td>\n",
       "      <td>95.635335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 Score</th>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Training Accuracy  Validation Accuracy\n",
       "Type                                             \n",
       "MSE Score         110.345501            95.635335\n",
       "R2 Score            0.609071             0.636898"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "results = pd.DataFrame({'Type': ['MSE Score', 'R2 Score'], \n",
    "                        'Training Accuracy': [linear_mse_train, linear_r2_train], \n",
    "                       'Validation Accuracy': [linear_mse_val, linear_r2_val]})\n",
    "\n",
    "# Set the index to 'Type' and print the results to the display.\n",
    "results.set_index('Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084367f6",
   "metadata": {},
   "source": [
    "#### Question 1 Response:\n",
    "Using a linear model did not produce good results for this dataset. \n",
    "\n",
    "The MSE scores for the training and validation sets were large at 110 and 95 respectively. This shows that the predicted values were quite far from the actual values for both sets.\n",
    "\n",
    "The R^2 training and validation accuracies were determined to be 0.61 and 0.64 respectively. Since the are close to each other and well below the maximum value of 1, it is clear that we are underfitting the data; we have low variance and high bias. This would suggest that the relationship is potentially non-linear; therefore, a linear model is not suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "#### Question 1 Response:\n",
    "Code was based on the provided class examples (particularly Linear Regression) as well as the Collab notebook for Lab 2. Aspects of the overall code structure and layout were modified to suit the specific assignment requirements.\n",
    "\n",
    "#### Question 2 Response:\n",
    "I completed the steps in the order recommended by the assigment (1->2->3->4->5).\n",
    "\n",
    "#### Question 3 Response:\n",
    "I did not use generative AI for the completion of this section.\n",
    "\n",
    "#### Question 4 Response:\n",
    "I did experience some challenges throughout the completion of this section:\n",
    "   - At first, I did not recall how to compute the mean squared error. I reference the the Lab 2 collab notebook to determine how to perform these calculations.\n",
    "   - I struggled recalling the syntax to set the index of the results DataFrame to the 'Type' column. I used Google to search the internet and help me recall to used the .set_index() method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "#### Part 1: Classification Observations\n",
    "\n",
    " - For the spam dataset we observed that in general, our model will exhibit better performance when we use a larger subset of data. When we used the full dataset, we achieved training and validation scores of 0.93 and 0.94 respectively. When we used two columns only, we achieved training and validation scores of 0.61 and 0.59 respectively. When we used only a 5% subset of the data, we achieved training and validation scores of 0.96 and 0.80 respectively.\n",
    " - Limiting the amount of data columns, resulted in a model of much higher bias (i.e. we were underfitting the data).\n",
    " - Limiting the amount of data rows, resulted in a model of much higher variance (i.e. we were overfitting the data).\n",
    " \n",
    " #### Part 2: Regression Observations\n",
    " \n",
    " - For the concrete dataset, the linear model we used resulted in R^2 training and validation accuracies of 0.61 and 0.64 respectively. Therefore, this model exhibited high bias (i.e. we were underfitting the data).\n",
    " - The mean squared error for the the training and validation sets were relatively large at 110 and 95 respectively.\n",
    " - This shows that there are cases where a linear model cannot accurately predict the relationship between variables and other methods need to be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "#### Reflection Response:\n",
    "I liked that this assignment gave me an opportunity to apply the linear models and validation methods that we have been learning throughout the first few weeks of the course. It gave me a better understanding of the concepts of bias/variance and how they can be impacted by the data and methods of modelling that we employ.\n",
    "\n",
    "I found it interesting to be able to quantify the impact of reducing the amount of data used from a particular source on the results. This made me realize how important it is to use as large of a dataset as possible when using linear modelling methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "47623d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Ridge MSE Training Accuracy</th>\n",
       "      <th>Ridge MSE Validation Accuracy</th>\n",
       "      <th>Ridge R^2 Training Accuracy</th>\n",
       "      <th>Ridge R^2 Validation Accuracy</th>\n",
       "      <th>Lasso MSE Training Accuracy</th>\n",
       "      <th>Lasso MSE Validation Accuracy</th>\n",
       "      <th>Lasso R^2 Training Accuracy</th>\n",
       "      <th>Lasso R^2 Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>110.345501</td>\n",
       "      <td>95.635335</td>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636898</td>\n",
       "      <td>110.345501</td>\n",
       "      <td>95.634971</td>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>110.345501</td>\n",
       "      <td>95.635334</td>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636898</td>\n",
       "      <td>110.345507</td>\n",
       "      <td>95.631698</td>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>110.345501</td>\n",
       "      <td>95.635324</td>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636898</td>\n",
       "      <td>110.346120</td>\n",
       "      <td>95.599545</td>\n",
       "      <td>0.609069</td>\n",
       "      <td>0.637034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>110.345501</td>\n",
       "      <td>95.635231</td>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636899</td>\n",
       "      <td>110.407340</td>\n",
       "      <td>95.335850</td>\n",
       "      <td>0.608852</td>\n",
       "      <td>0.638035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>110.345502</td>\n",
       "      <td>95.634301</td>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636902</td>\n",
       "      <td>112.093055</td>\n",
       "      <td>95.114791</td>\n",
       "      <td>0.602880</td>\n",
       "      <td>0.638874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>110.345597</td>\n",
       "      <td>95.625173</td>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636937</td>\n",
       "      <td>151.368492</td>\n",
       "      <td>126.142568</td>\n",
       "      <td>0.463736</td>\n",
       "      <td>0.521070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alpha  Ridge MSE Training Accuracy  Ridge MSE Validation Accuracy  \\\n",
       "0    0.001                   110.345501                      95.635335   \n",
       "1    0.010                   110.345501                      95.635334   \n",
       "2    0.100                   110.345501                      95.635324   \n",
       "3    1.000                   110.345501                      95.635231   \n",
       "4   10.000                   110.345502                      95.634301   \n",
       "5  100.000                   110.345597                      95.625173   \n",
       "\n",
       "   Ridge R^2 Training Accuracy  Ridge R^2 Validation Accuracy  \\\n",
       "0                     0.609071                       0.636898   \n",
       "1                     0.609071                       0.636898   \n",
       "2                     0.609071                       0.636898   \n",
       "3                     0.609071                       0.636899   \n",
       "4                     0.609071                       0.636902   \n",
       "5                     0.609071                       0.636937   \n",
       "\n",
       "   Lasso MSE Training Accuracy  Lasso MSE Validation Accuracy  \\\n",
       "0                   110.345501                      95.634971   \n",
       "1                   110.345507                      95.631698   \n",
       "2                   110.346120                      95.599545   \n",
       "3                   110.407340                      95.335850   \n",
       "4                   112.093055                      95.114791   \n",
       "5                   151.368492                     126.142568   \n",
       "\n",
       "   Lasso R^2 Training Accuracy  Lasso R^2 Validation Accuracy  \n",
       "0                     0.609071                       0.636899  \n",
       "1                     0.609071                       0.636912  \n",
       "2                     0.609069                       0.637034  \n",
       "3                     0.608852                       0.638035  \n",
       "4                     0.602880                       0.638874  \n",
       "5                     0.463736                       0.521070  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "alpha = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "ridge_mse_train = []\n",
    "ridge_mse_val = []\n",
    "ridge_r2_train = []\n",
    "ridge_r2_val = []\n",
    "lasso_mse_train = []\n",
    "lasso_mse_val = []\n",
    "lasso_r2_train = []\n",
    "lasso_r2_val = []\n",
    "\n",
    "for a in alpha:\n",
    "    # Initialize and train a Ridge regression model.\n",
    "    ridge_model = Ridge(alpha=a).fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions.\n",
    "    y_pred_train_ridge = ridge_model.predict(X_train)\n",
    "    y_pred_val_ridge = ridge_model.predict(X_val)\n",
    "    \n",
    "    # Evaluate the ridge regression model.\n",
    "    ridge_mse_train.append(mean_squared_error(y_train, y_pred_train_ridge))\n",
    "    ridge_mse_val.append(mean_squared_error(y_val, y_pred_val_ridge))\n",
    "    ridge_r2_train.append(ridge_model.score(X_train, y_train))\n",
    "    ridge_r2_val.append(ridge_model.score(X_val, y_val))\n",
    "    \n",
    "    # Initialize and train a lasso regression model.\n",
    "    lasso_model = Lasso(alpha=a).fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions.\n",
    "    y_pred_train_lasso = lasso_model.predict(X_train)\n",
    "    y_pred_val_lasso = lasso_model.predict(X_val)\n",
    "\n",
    "    # Evaluate the lass regression model.\n",
    "    lasso_mse_train.append(mean_squared_error(y_train, y_pred_train_lasso))\n",
    "    lasso_mse_val.append(mean_squared_error(y_val, y_pred_val_lasso))\n",
    "\n",
    "    lasso_r2_train.append(lasso_model.score(X_train, y_train))\n",
    "    lasso_r2_val.append(lasso_model.score(X_val, y_val))\n",
    "\n",
    "results = pd.DataFrame({'Alpha': alpha, \n",
    "                       'Ridge MSE Training Accuracy': ridge_mse_train,\n",
    "                       'Ridge MSE Validation Accuracy': ridge_mse_val,\n",
    "                       'Ridge R^2 Training Accuracy': ridge_r2_train,\n",
    "                       'Ridge R^2 Validation Accuracy': ridge_r2_val,\n",
    "                       'Lasso MSE Training Accuracy': lasso_mse_train,\n",
    "                       'Lasso MSE Validation Accuracy': lasso_mse_val,\n",
    "                       'Lasso R^2 Training Accuracy': lasso_r2_train,\n",
    "                       'Lasso R^2 Validation Accuracy': lasso_r2_val})\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    "As per the results table, the alpha values that gave the best results for each method were:\n",
    "- Alpha = 100, resulting in a R^2 validation accuracy of 0.636937 (for the Ridge Method)\n",
    "- Alpha = 10, resulting in a R^2 validation accuracy of 0.638874 (for the Lasso Method)\n",
    "\n",
    "This is still poor performance as it is very far from the maximum R^2 value of 1.0. We are still underfitting the data (we have low variance and high bias). This likely confirms our suspicion that the data is not linearly related and another modelling technique will need to be used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
